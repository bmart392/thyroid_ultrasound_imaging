"""
Contains code for ImageData class.
"""

# Import standard libraries
from cv2 import findContours, RETR_EXTERNAL, CHAIN_APPROX_NONE, contourArea, moments
from numpy import sum, uint8, array, frombuffer, reshape, product
from rospy import Time
from sensor_msgs.msg import Image
from cv_bridge import CvBridge, CvBridgeError
from thyroid_ultrasound_messages.msg import image_data_message

# Import custom functions and constants
from thyroid_ultrasound_imaging_support.ImageData.BridgeImageDataMessageConstants import *
from thyroid_ultrasound_imaging_support.ImageData.bridge_list_of_points_multi_array import \
    bridge_list_of_points_multi_array
from thyroid_ultrasound_imaging_support.ImageData.bridge_list_of_contours_multi_array import \
    bridge_list_of_contours_multi_array

from thyroid_ultrasound_imaging_support.ImageData.single_line_representations import \
    create_single_line_simple_data, create_single_line_array_data, create_single_line_time_stamp, \
    rebuild_data

# Define constants for bridging between the object and its string
IMAGE_TITLE: str = "image_title"
IMAGE_COLOR: str = "image_color"
IMAGE_SIZE_X: str = "image_size_x"
IMAGE_SIZE_Y: str = "image_size_y"
SEGMENTATION_INITIALIZATION_MASK: str = "segmentation_initialization_mask"
ORIGINAL_IMAGE: str = "original_image"
CROPPED_IMAGE: str = "cropped_image"
COLORIZED_IMAGE: str = "colorized_image"
PRE_PROCESSED_IMAGE: str = "pre_processed_image"
IMAGE_MASK: str = "image_mask"
EXPANDED_IMAGE_MASK: str = "expanded_image_mask"
SURE_FOREGROUND_MASK: str = "sure_foreground_mask"
SURE_BACKGROUND_MASK: str = "sure_background_mask"
PROBABLE_FOREGROUND_MASK: str = "probable_foreground_mask"
CONTOURS_IN_IMAGE: str = "contours_in_image"
CONTOUR_CENTROIDS: str = "contour_centroids"
IMAGE_CAPTURE_TIME: str = "image_capture_time"


class ImageData:
    """
    A class for holding image data and its filtered components.

    Attributes:
        image_title
            A title to display for the image
        image_color
            The color coding of the image according to custom constants

        image_size_x
            The original image size in the x direction
        image_size_y
            The original image size in the y direction

        segmentation_initialization_mask
            The mask to use to initialize the segmentation of the image.

        original_image
            The original image
        cropped_image
            The cropped version of the original image
        colorized_image
            The recolored version of the cropped image
        pre_processed_image
            The pre-processed version of the colorized image
        image_mask
            The binary mask generated by segmenting the pre-processed image
        expanded_image_mask
            The binary mask generated by expanding the image_mask to the original image size
        sure_foreground_mask
            The binary mask generated by shrinking the regions of the expanded image mask
        sure_background_mask
            The binary mask generated by expanding the regions of the image mask and inverting the mask
        probable_foreground_mask
            The binary mask generated as the difference between the sure foreground mask and the sure background mask

        contours_in_image
            A list of contours found in the expanded image mask
        contour_centroids
            A list of centroids of the contours found in the image

        image_capture_time
            A timestamp of when the image was captured

    """

    def __init__(self, image_data: array = None,
                 image_color: int = None,
                 image_title: str = "",
                 image_capture_time: Time = None,
                 segmentation_initialization_mask: array = None,
                 image_data_msg: image_data_message = None,
                 image_data_str: str = None,
                 display_error_messages: bool = False):
        """
        Creates a new ImageData object.

        New ImageData objects can be built in two ways. First, with an array representing a 2D image. Second, with an
        ImageDataMessage object.

        Parameters
        ----------
        image_data
            an array representing the image to use to create the ImageData object.
        image_color
            a constant representing the color scheme of the image.
        image_title
            a title for the image.
        image_capture_time
            a time stamp marking when the image was captured.
        segmentation_initialization_mask
            the mask used to initialize the segmentation of the image stored in this object.
            This is not used in all types of image filters.
        image_data_msg
            an image_data ros message object.
        image_data_str
            a string representing all the information stored in an image object.
        """

        # Define error behaviour for all cases
        self.display_error_messages = display_error_messages

        # Define an empty initialized segmentation mask in case none is given later
        self.segmentation_initialization_mask = array([])

        # --------------------------------------------------------------
        # Create empty parameters for use by the filters
        # !!! Order of parameters represent order of operations expected
        # --------------------------------------------------------------
        self.original_image = array([])
        self.cropped_image = None
        self.colorized_image = None
        self.pre_processed_image = None
        self.image_mask = None
        self.expanded_image_mask = None
        self.sure_foreground_mask = None
        self.sure_background_mask = None
        self.probable_foreground_mask = None

        # If the image data object is being created from an image_data message object
        if image_data_msg is not None:

            # Fill in the object properties from the message fields
            self.bridge_image_data_and_message(TO_OBJECT, message=image_data_msg)

        # If the image data object is being created from an image data string
        elif image_data_str is not None:

            # Fill in the object properties from the string
            self.bridge_string_to_object(image_data_str)

        # Otherwise
        else:

            # Check that an image has been given for object creation
            if image_data is None:
                raise Exception("An ImageData object could not be created because an image was not provided.")

            # Save the mask used to initialize the segmentation of this image
            if segmentation_initialization_mask is not None:
                self.segmentation_initialization_mask = segmentation_initialization_mask

            # Save the image given
            self.original_image = image_data

            # Save the time the image was taken or save the current time
            if image_capture_time is not None:
                self.image_capture_time = image_capture_time
            else:
                self.image_capture_time = Time.now()

            # Define basic parameters of the image
            self.image_title = image_title
            self.image_color = image_color

            # Create empty parameters for storing the centroids and contours
            self.contours_in_image = []
            self.contour_centroids = []

        # Calculate the size of the image regardless of how the object is created
        self.image_size_x = self.original_image.shape[1]
        self.image_size_y = self.original_image.shape[0]

    def convert_to_message(self):
        """
        Converts the existing data object into an equivalent ROS message.
        """

        return self.bridge_image_data_and_message(TO_MESSAGE)

    def generate_contours_in_image(self):
        """
        Generate contours from the 2-dimensional binary image stored in the expanded_image_mask field. Stores the
        result in the contours_in_image field of the current object.
        """

        # Define an empty list to store the result
        self.contours_in_image = []

        # Only create the contours if the expanded image mask has been created
        # AND
        # the expanded image mask contains any contours.
        if self.expanded_image_mask is not None and not sum(self.expanded_image_mask) == 0:

            # Use a built-in function to generate the contours
            contours_in_image, hierarchy = findContours(
                self.expanded_image_mask.astype(uint8),
                RETR_EXTERNAL,
                CHAIN_APPROX_NONE
            )

            # Sort the resulting contours by area with the largest contour first
            temp_contours = sorted(contours_in_image,
                                   key=contourArea,
                                   reverse=True)

            # Define a minimum area requirement
            minimum_contour_area = 10

            # Only add contours to the final list that exceed the minimum contour area requirement
            for contour in temp_contours:
                if contourArea(contour) > minimum_contour_area:
                    self.contours_in_image.append(contour)

    def calculate_image_centroids(self):
        """
        Calculate the centroids of each contour in the list of contours. Returns the result as a
        list of (x, y) coordinates.
        """

        # create empty array to return when no centroids are found
        result = []

        # calculate the centroid of each contour
        for contour in self.contours_in_image:
            temp_moments = moments(contour)
            temp_centroid_x = int(temp_moments["m10"] / temp_moments["m00"])
            temp_centroid_y = int(temp_moments["m01"] / temp_moments["m00"])
            self.contour_centroids.append((temp_centroid_x, temp_centroid_y))

        # append the centroid of the largest contour found
        result.append((self.contours_in_image[0], self.contour_centroids[0]))

        # if 2 or more contours were found and the second contour also big, include it
        if len(self.contour_centroids) >= 2:
            if (contourArea(self.contours_in_image[1]) >=
                    0.9 * contourArea(self.contours_in_image[0])):
                result.append((self.contours_in_image[1], self.contour_centroids[1]))

        return result

    def bridge_image_data_and_message(self, direction: int, message: image_data_message = None):
        """
        Convert an image data object into a ROS image data message and vice versa.
        """

        # Fill in the basic image message information
        if direction == TO_MESSAGE:

            # Create a new message object
            message = image_data_message()

            message.image_title = self.image_title
            message.image_color = self.image_color

            message.header.stamp = self.image_capture_time

            message.image_size_x = self.image_size_x
            message.image_size_y = self.image_size_y

            message.contours_in_image = bridge_list_of_contours_multi_array(TO_MESSAGE,
                                                                            list_of_contours=self.contours_in_image)
            message.contour_centroids = bridge_list_of_points_multi_array(TO_MESSAGE,
                                                                          list_of_points=self.contour_centroids)

        # Fill in the basic object information
        elif direction == TO_OBJECT:

            # Check that the proper input is not None
            if message is None:
                raise Exception("message cannot be None when converting to object.")

            self.image_title = message.image_title
            self.image_color = message.image_color

            self.image_capture_time = message.header.stamp

            self.image_size_x = message.image_size_x
            self.image_size_y = message.image_size_y

            self.contours_in_image = bridge_list_of_contours_multi_array(TO_OBJECT,
                                                                         array_message=message.contours_in_image)
            self.contour_centroids = bridge_list_of_points_multi_array(TO_OBJECT,
                                                                       array_message=message.contour_centroids)
        else:
            raise Exception("Invalid direction given.")

        # --------------------------------------------------------------
        # Convert each image field to its corresponding message field OR
        # convert each message field to its corresponding image field.
        # --------------------------------------------------------------

        # Segmentation Initialization Mask
        temp_result = self.convert_single_field(direction=direction, image_field=self.segmentation_initialization_mask,
                                                message_field=message.segmentation_initialization_mask,
                                                error_message="Segmentation Initialization Mask")
        message.segmentation_initialization_mask = temp_result[1]
        self.segmentation_initialization_mask = temp_result[0]

        # Original Image
        temp_result = self.convert_single_field(direction=direction, image_field=self.original_image,
                                                message_field=message.original_image,
                                                error_message="Original Image")
        message.original_image = temp_result[1]
        self.original_image = temp_result[0]

        # Cropped Image
        temp_result = self.convert_single_field(direction=direction, image_field=self.cropped_image,
                                                message_field=message.cropped_image,
                                                error_message="Cropped Image")
        message.cropped_image = temp_result[1]
        self.cropped_image = temp_result[0]

        # Colorized Image
        temp_result = self.convert_single_field(direction=direction, image_field=self.colorized_image,
                                                message_field=message.colorized_image,
                                                error_message="Colorized Image")
        message.colorized_image = temp_result[1]
        self.colorized_image = temp_result[0]

        # Pre-process Image
        temp_result = self.convert_single_field(direction=direction, image_field=self.pre_processed_image,
                                                message_field=message.pre_processed_image,
                                                error_message="Pre-processed Image")
        message.pre_processed_image = temp_result[1]
        self.pre_processed_image = temp_result[0]

        # Image Mask
        temp_result = self.convert_single_field(direction=direction, image_field=self.image_mask,
                                                message_field=message.image_mask,
                                                error_message="Image Mask")
        message.image_mask = temp_result[1]
        self.image_mask = temp_result[0]

        # Expanded Image Mask
        temp_result = self.convert_single_field(direction=direction, image_field=self.expanded_image_mask,
                                                message_field=message.expanded_image_mask,
                                                error_message="Expanded Image Mask")
        message.expanded_image_mask = temp_result[1]
        self.expanded_image_mask = temp_result[0]

        # Sure Foreground Image Mask
        temp_result = self.convert_single_field(direction=direction, image_field=self.sure_foreground_mask,
                                                message_field=message.sure_foreground_mask,
                                                error_message="Sure Foreground Image Mask")
        message.sure_foreground_mask = temp_result[1]
        self.sure_foreground_mask = temp_result[0]

        # Sure Background Image Mask
        temp_result = self.convert_single_field(direction=direction, image_field=self.sure_background_mask,
                                                message_field=message.sure_background_mask,
                                                error_message="Sure Background Image Mask")
        message.sure_background_mask = temp_result[1]
        self.sure_background_mask = temp_result[0]

        # Probable Foreground Image Mask
        temp_result = self.convert_single_field(direction=direction, image_field=self.probable_foreground_mask,
                                                message_field=message.probable_foreground_mask,
                                                error_message="Probable Foreground Image Mask")
        message.probable_foreground_mask = temp_result[1]
        self.probable_foreground_mask = temp_result[0]

        # Return the resulting message if required
        if direction == TO_MESSAGE:
            return message

    def convert_single_field(self, direction, image_field, message_field, error_message):

        # Create a bridge object to convert the image arrays to image message objects
        bridge = CvBridge()

        try:
            if direction == TO_MESSAGE:
                message_field = Image()
                if image_field is not None:
                    if len(image_field) != 0:
                        message_field = bridge.cv2_to_imgmsg(image_field)
            elif direction == TO_OBJECT:
                image_field = None
                if message_field is not None:
                    if len(message_field.data) != 0:
                        image_field = frombuffer(message_field.data, dtype=uint8)
                        if message_field.encoding == "8UC1":
                            image_field = reshape(image_field, (message_field.height, message_field.width))
                        elif message_field.encoding == "8UC3" or \
                                message_field.encoding == "rgb8" or \
                                message_field.encoding == "bgr8":
                            image_field = reshape(image_field, (message_field.height, message_field.width, 3))
                        else:
                            raise Exception("Unknown encoding given.")
            else:
                raise Exception("Invalid direction given.")
            return image_field, message_field
        except CvBridgeError:
            if self.display_error_messages:
                print(error_message + " could not be converted.")

    def bridge_object_to_string(self) -> str:

        # Define the variable that will be returned
        return_string = ""

        # Add the image title
        return_string = create_single_line_simple_data(IMAGE_TITLE, self.image_title, return_string)

        # Add the image color
        return_string = create_single_line_simple_data(IMAGE_COLOR, self.image_color, return_string)

        # Add the image size in x
        return_string = create_single_line_simple_data(IMAGE_SIZE_X, self.image_size_x, return_string)

        # Add the image size in y
        return_string = create_single_line_simple_data(IMAGE_SIZE_Y, self.image_size_y, return_string)

        # Add the segmentation_initialization_mask
        return_string = create_single_line_array_data(SEGMENTATION_INITIALIZATION_MASK,
                                                      self.segmentation_initialization_mask, return_string)

        # Add the original image
        return_string = create_single_line_array_data(ORIGINAL_IMAGE, self.original_image, return_string)

        # Add the cropped image
        return_string = create_single_line_array_data(CROPPED_IMAGE, self.cropped_image, return_string)

        # Add the colorized image
        return_string = create_single_line_array_data(COLORIZED_IMAGE, self.colorized_image, return_string)

        # Add the pre-processed image
        return_string = create_single_line_array_data(PRE_PROCESSED_IMAGE, self.pre_processed_image,
                                                      return_string)

        # Add the image mask
        return_string = create_single_line_array_data(IMAGE_MASK, self.image_mask, return_string)

        # Add the expanded image mask
        return_string = create_single_line_array_data(EXPANDED_IMAGE_MASK, self.expanded_image_mask,
                                                      return_string)

        # Add the sure foreground mask
        return_string = create_single_line_array_data(SURE_FOREGROUND_MASK, self.sure_foreground_mask,
                                                      return_string)

        # Add the sure background mask
        return_string = create_single_line_array_data(SURE_BACKGROUND_MASK, self.sure_background_mask,
                                                      return_string)

        # Add the probable foreground mask
        return_string = create_single_line_array_data(PROBABLE_FOREGROUND_MASK, self.probable_foreground_mask,
                                                      return_string)

        # Add the contours in image
        return_string = create_single_line_array_data(CONTOURS_IN_IMAGE, self.contours_in_image, return_string)

        # Add the centroids in the image
        return_string = create_single_line_array_data(CONTOUR_CENTROIDS, self.contour_centroids, return_string)

        # Add the image capture time
        return create_single_line_time_stamp(IMAGE_CAPTURE_TIME, self.image_capture_time, return_string)

    def bridge_string_to_object(self, object_as_string):

        # Remove the carriage return character at the end of the string
        object_as_string = object_as_string[:-1]

        # Pull each field from the string by splitting on the carriage returns
        object_fields = object_as_string.split("\n")

        # Fill in each field from the corresponding string
        field_name, self.image_title = rebuild_data(object_fields[0])
        field_name, self.image_color = rebuild_data(object_fields[1])
        field_name, self.image_size_x = rebuild_data(object_fields[2])
        field_name, self.image_size_y = rebuild_data(object_fields[3])
        field_name, self.segmentation_initialization_mask = rebuild_data(object_fields[4])
        field_name, self.original_image = rebuild_data(object_fields[5])
        field_name, self.cropped_image = rebuild_data(object_fields[6])
        field_name, self.colorized_image = rebuild_data(object_fields[7])
        field_name, self.pre_processed_image = rebuild_data(object_fields[8])
        field_name, self.image_mask = rebuild_data(object_fields[9])
        field_name, self.expanded_image_mask = rebuild_data(object_fields[10])
        field_name, self.sure_foreground_mask = rebuild_data(object_fields[11])
        field_name, self.sure_background_mask = rebuild_data(object_fields[12])
        field_name, self.probable_foreground_mask = rebuild_data(object_fields[13])
        field_name, self.contours_in_image = rebuild_data(object_fields[14])
        field_name, self.contour_centroids = rebuild_data(object_fields[15])
        field_name, self.image_capture_time = rebuild_data(object_fields[16])


